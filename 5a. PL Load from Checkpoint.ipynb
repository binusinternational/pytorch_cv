{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "swedish-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False # in case your autocomplete does not work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-girlfriend",
   "metadata": {},
   "source": [
    "I mentioned about logging in the previous article, but we only displayed it in the Tensorboard.\n",
    "Now, can we pick up what we have left previously? Why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-gender",
   "metadata": {},
   "source": [
    "# Checkpoint loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-costa",
   "metadata": {},
   "source": [
    "The checkpoints are stored in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aging-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mlightning_logs/\u001b[00m\r\n",
      "├── \u001b[01;34mversion_0\u001b[00m\r\n",
      "│   ├── \u001b[01;34mcheckpoints\u001b[00m\r\n",
      "│   │   └── epoch=9-step=5500.ckpt\r\n",
      "│   ├── events.out.tfevents.1654332948.ubuntu-OMEN.110229.0\r\n",
      "│   ├── events.out.tfevents.1654332989.ubuntu-OMEN.110229.1\r\n",
      "│   └── hparams.yaml\r\n",
      "├── \u001b[01;34mversion_1\u001b[00m\r\n",
      "│   ├── \u001b[01;34mcheckpoints\u001b[00m\r\n",
      "│   │   └── epoch=9-step=5500.ckpt\r\n",
      "│   ├── events.out.tfevents.1654332995.ubuntu-OMEN.110229.2\r\n",
      "│   ├── events.out.tfevents.1654333035.ubuntu-OMEN.110229.3\r\n",
      "│   └── hparams.yaml\r\n",
      "├── \u001b[01;34mversion_2\u001b[00m\r\n",
      "│   ├── \u001b[01;34mcheckpoints\u001b[00m\r\n",
      "│   │   └── epoch=9-step=5500.ckpt\r\n",
      "│   ├── events.out.tfevents.1654333539.ubuntu-OMEN.115365.0\r\n",
      "│   ├── events.out.tfevents.1654333578.ubuntu-OMEN.115365.1\r\n",
      "│   └── hparams.yaml\r\n",
      "└── \u001b[01;34mversion_3\u001b[00m\r\n",
      "    ├── \u001b[01;34mcheckpoints\u001b[00m\r\n",
      "    │   └── epoch=9-step=5500.ckpt\r\n",
      "    ├── events.out.tfevents.1654333584.ubuntu-OMEN.115365.2\r\n",
      "    ├── events.out.tfevents.1654333632.ubuntu-OMEN.115365.3\r\n",
      "    └── hparams.yaml\r\n",
      "\r\n",
      "8 directories, 16 files\r\n"
     ]
    }
   ],
   "source": [
    "! tree lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "impressed-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl # --> NEW\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics.functional import accuracy\n",
    "# from pytorch_lightning.metrics.functional import accuracy # --> This is NEW\n",
    "from torch.utils.data import DataLoader, random_split # random_split is NEW\n",
    "\n",
    "import sps # from https://github.com/IssamLaradji/sps --> a new optimizer\n",
    "\n",
    "# 2. Copy the model here\n",
    "\n",
    "class FNN(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, input_size, num_neurons_hidden1,  num_neurons_hidden2, output_size, optimizer='adam'):\n",
    "        # Copy paste from the previous article\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(input_size,num_neurons_hidden1)\n",
    "        self.hidden_layer1 = nn.Linear(num_neurons_hidden1,num_neurons_hidden2)\n",
    "        self.output_layer = nn.Linear(num_neurons_hidden2,output_size)\n",
    "        \n",
    "        tf_resize = transforms.Resize((28,28)) # make sure that all loaded images have these dimensions\n",
    "        tf_totensor = transforms.ToTensor() # Why? pytorch uses this datatype\n",
    "        tf_normalize = transforms.Normalize(mean=(.5,),std=(.5,)) # this is rather tricky to explain. I'll explain it after we compose all these transformations\n",
    "\n",
    "        self.tf_compose = transforms.Compose([tf_resize,tf_totensor,tf_normalize])\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # Copy paste from the previous article\n",
    "        y = nn.functional.relu(self.input_layer(x))\n",
    "        y = nn.functional.relu(self.hidden_layer1(y))\n",
    "        y = self.output_layer(y)\n",
    "        return y\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Copy paste from the previous article\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.view(inputs.shape[0],-1)\n",
    "        \n",
    "        outputs = self.forward(inputs)\n",
    "        loss = nn.functional.cross_entropy(outputs,labels) # --> NEW. Using nn.CrossEntropyLoss\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # This is new, but the structure is the same as training_step\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.view(inputs.shape[0],-1)\n",
    "        \n",
    "        outputs = self.forward(inputs)\n",
    "        loss = nn.functional.cross_entropy(outputs,labels)\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = accuracy(preds, labels) # --> NEW\n",
    "        \n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # This is new, but the structure is the same as test_step\n",
    "        # but I replace val_loss --> test_loss etc\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.view(inputs.shape[0],-1)\n",
    "        \n",
    "        outputs = self.forward(inputs)\n",
    "        loss = nn.functional.cross_entropy(outputs,labels)\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        acc = accuracy(preds, labels)\n",
    "        \n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        if self.optimizer == 'sps':\n",
    "            optimizer = sps.Sps(self.parameters()) # No learning rate to be set :D\n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download once\n",
    "        datasets.MNIST(root='./', train=True, download=True)\n",
    "        datasets.MNIST(root='./', train=False, download=True)\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        # split, transform, secretly move to GPU (if needed) by PL (not by us)\n",
    "        if stage == 'fit' or stage is None:\n",
    "            mnist_full = datasets.MNIST(root='./', train=True, transform=self.tf_compose)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "            \n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.mnist_test = datasets.MNIST(root='./', train=False, transform=self.tf_compose)\n",
    "            \n",
    "    def train_dataloader(self): \n",
    "        return DataLoader(self.mnist_train, batch_size=100, num_workers=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=100, num_workers=2)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=100, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "removed-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load from checkpoint\n",
    "\n",
    "model = FNN.load_from_checkpoint(\n",
    "    checkpoint_path='./lightning_logs/version_0/checkpoints/epoch=9-step=5500.ckpt',\n",
    "    input_size=784,\n",
    "    num_neurons_hidden1=100,\n",
    "    num_neurons_hidden2=50,\n",
    "    output_size=10\n",
    ") # version 0 is my Adam implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-plate",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-merchant",
   "metadata": {},
   "source": [
    "After loading the model, we can perform, for example, inference as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "working-negotiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9b7dec3d30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterator = iter(\n",
    "    DataLoader(datasets.MNIST(root='./', train=False, download=True, transform=model.tf_compose),\n",
    "               batch_size=1\n",
    "              )\n",
    ")\n",
    "image = next(iterator)\n",
    "image = image[0][0]\n",
    "plt.imshow(image.numpy().transpose(1,2,0),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "right-report",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(image.view(image.size(0),-1)).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-validity",
   "metadata": {},
   "source": [
    "# Continue Training\n",
    "\n",
    "We can also contine training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "atlantic-baltimore",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type   | Params\n",
      "-----------------------------------------\n",
      "0 | input_layer   | Linear | 78.5 K\n",
      "1 | hidden_layer1 | Linear | 5.0 K \n",
      "2 | output_layer  | Linear | 510   \n",
      "-----------------------------------------\n",
      "84.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "84.1 K    Total params\n",
      "0.336     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardimas/miniconda3/envs/pytorch_tutorial/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ardimas/miniconda3/envs/pytorch_tutorial/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ardimas/miniconda3/envs/pytorch_tutorial/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef34f2e28de466084f4a44e54556c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    trainer = pl.Trainer(gpus=1,max_epochs=1)\n",
    "except Exception as e:\n",
    "    # most likely due to GPU, so fallback to non GPU\n",
    "    print(e)\n",
    "    trainer = pl.Trainer(max_epochs=1)\n",
    "    \n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tender-translator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 111424), started 0:21:41 ago. (Use '!kill 111424' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-382f720ae671d16e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-382f720ae671d16e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "economic-trash",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardimas/miniconda3/envs/pytorch_tutorial/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1446: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `test(ckpt_path='best')` to use and best model checkpoint and avoid this warning or `ckpt_path=trainer.checkpoint_callback.last_model_path` to use the last model.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at /home/ardimas/Documents/PROJECTS/pytorch_cv/lightning_logs/version_4/checkpoints/epoch=0-step=550.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/ardimas/Documents/PROJECTS/pytorch_cv/lightning_logs/version_4/checkpoints/epoch=0-step=550.ckpt\n",
      "/home/ardimas/miniconda3/envs/pytorch_tutorial/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d80710bebb4854a55a1c80039d1842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9678000211715698\n",
      "        test_loss           0.1038515716791153\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.1038515716791153, 'test_acc': 0.9678000211715698}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-handling",
   "metadata": {},
   "source": [
    "Notice that the validation and test accuracy are already good even the number of epochs is only one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-focus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
